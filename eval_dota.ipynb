{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0831be09",
   "metadata": {
    "id": "1866a12a"
   },
   "source": [
    "# Transformer Dose Calculation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07237bb3",
   "metadata": {
    "id": "EPNNAHcrOUXd"
   },
   "source": [
    "## Import libraries and define auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908536ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3451,
     "status": "ok",
     "timestamp": 1622220341066,
     "user": {
      "displayName": "Oscar Pastor Serrano",
      "photoUrl": "",
      "userId": "05646652561813059794"
     },
     "user_tz": -120
    },
    "id": "44dc2db2",
    "outputId": "1ba8f51e-9e93-411a-c432-0ecc27ff44a1"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "from models import dota_energies\n",
    "from preprocessing import DataRescaler\n",
    "from generators import DataGenerator\n",
    "from evaluation import infer, from_file\n",
    "from plot import plot_slice, plot_beam\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c33ff8b",
   "metadata": {
    "id": "XpnpveIhrxPp"
   },
   "source": [
    "## Load hyperparameters and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50870622",
   "metadata": {
    "id": "eRlPmU_xJERL"
   },
   "outputs": [],
   "source": [
    "# Load model and data hyperparameters.\n",
    "with open(\"./hyperparam.json\", \"r\") as hfile:\n",
    "    param = json.load(hfile)\n",
    "\n",
    "# Prepare input data.\n",
    "path = \"./data/training/\"\n",
    "path_test = \"./data/test/\"\n",
    "path_weights = \"./weights/weights.ckpt\"\n",
    "filename = path + \"train.h5\"\n",
    "filename_test = path_test + \"test.h5\"\n",
    "filename_pba = path_test + 'testPBA.h5'\n",
    "with h5py.File(filename_test, 'r') as fh:\n",
    "    testIDs = [*range(fh['geometry'].shape[-1])]\n",
    "\n",
    "# Load normalization constants.\n",
    "scaler = DataRescaler(path, filename=filename)\n",
    "scaler.load(inputs=True, outputs=True)\n",
    "scale = {\"y_min\":scaler.y_min, \"y_max\":scaler.y_max,\n",
    "        \"x_min\":scaler.x_min, \"x_max\":scaler.x_max,\n",
    "        \"e_min\":70, \"e_max\":220}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f22243e",
   "metadata": {
    "id": "bc62beca"
   },
   "source": [
    "## Define and train the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858e42df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 449,
     "status": "ok",
     "timestamp": 1622220733287,
     "user": {
      "displayName": "Oscar Pastor Serrano",
      "photoUrl": "",
      "userId": "05646652561813059794"
     },
     "user_tz": -120
    },
    "id": "9XGG1HuSIlmW",
    "outputId": "8ddf5dd9-8560-4414-d912-e4672d356a42"
   },
   "outputs": [],
   "source": [
    "transformer = dota_energies(\n",
    "    num_tokens=param[\"num_tokens\"],\n",
    "    input_shape=param[\"data_shape\"],\n",
    "    projection_dim=param[\"projection_dim\"],\n",
    "    num_heads=param[\"num_heads\"],\n",
    "    num_transformers=param[\"num_transformers\"], \n",
    "    kernel_size=param[\"kernel_size\"],\n",
    "    causal=True\n",
    ")\n",
    "transformer.summary()\n",
    "\n",
    "# Load weights from checkpoint.\n",
    "transformer.load_weights(path_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66dae0b",
   "metadata": {
    "id": "136ebcdd"
   },
   "source": [
    "## Evaluate the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8289c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gamma results\n",
    "gamma_results = np.load('./utils/eval/gamma_analysis.npz')\n",
    "gamma_passrate = gamma_results[\"arr_1\"]\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(gamma_passrate[0], 20)\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Mean: {np.mean(gamma_passrate[0])}\")\n",
    "print(f\"Stdev: {np.std(gamma_passrate[0])}\")\n",
    "print(f\"Min: {np.amin(gamma_passrate[0])}\")\n",
    "print(f\"Max: {np.amax(gamma_passrate[0])}\")\n",
    "\n",
    "# Print worst sample IDs\n",
    "gamma_IDs = gamma_results[\"arr_0\"]\n",
    "print(f\"Worst IDs: {gamma_IDs[0,:10]}\")\n",
    "print(f\"Worst pass rate: {gamma_passrate[0,8]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8310ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, prediction, ground_truth = infer(transformer, testIDs[1524], filename_test, scale)\n",
    "plot_beam(inputs, ground_truth, prediction,  gamma_evaluation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dcc332",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, prediction, ground_truth = infer(transformer, testIDs[2082], filename_test, scale)\n",
    "plot_slice(inputs, ground_truth, prediction, scale, savefig=True)\n",
    "inputs, prediction, ground_truth = infer(transformer, testIDs[1951], filename_test, scale)\n",
    "plot_slice(inputs, ground_truth, prediction, scale, savefig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2eb1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, prediction, ground_truth = infer(transformer, testIDs[48], filename_test, scale)\n",
    "plot_slice(inputs, ground_truth, prediction, scale, savefig=True)\n",
    "inputs, prediction, ground_truth = infer(transformer, testIDs[1776], filename_test, scale)\n",
    "plot_slice(inputs, ground_truth, prediction, scale, savefig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c6387",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, prediction, ground_truth = from_file(filename_pba, testIDs[2082], filename_test)\n",
    "plot_slice(inputs, ground_truth, prediction, scale, cutoff=0.1, savefig=True)\n",
    "inputs, prediction, ground_truth = from_file(filename_pba, testIDs[1951], filename_test)\n",
    "plot_slice(inputs, ground_truth, prediction, scale, cutoff=0.1, savefig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948299c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, prediction, ground_truth = from_file(filename_pba, testIDs[48], filename_test)\n",
    "plot_slice(inputs, ground_truth, prediction, scale, cutoff=0.1, savefig=True)\n",
    "inputs, prediction, ground_truth = from_file(filename_pba, testIDs[1776], filename_test)\n",
    "plot_slice(inputs, ground_truth, prediction, scale, cutoff=0.1, savefig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f14865",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, prediction, ground_truth = from_file(filename_pba, testIDs[2082], filename_test)\n",
    "plot_slice(inputs, ground_truth, prediction, scale, cutoff=0.1, gamma_slice=False, savefig=True)\n",
    "inputs, prediction, ground_truth = infer(transformer, testIDs[2082], filename_test, scale)\n",
    "plot_slice(inputs, ground_truth, prediction, scale, cutoff=0.1, gamma_slice=False, savefig=True)\n",
    "inputs, prediction, ground_truth = from_file(filename_pba, testIDs[48], filename_test)\n",
    "plot_slice(inputs, ground_truth, prediction, scale, cutoff=0.1, gamma_slice=False, savefig=True)\n",
    "inputs, prediction, ground_truth = infer(transformer, testIDs[48], filename_test, scale)\n",
    "plot_slice(inputs, ground_truth, prediction, scale, cutoff=0.1, gamma_slice=False, savefig=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dose_transformer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-5.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
